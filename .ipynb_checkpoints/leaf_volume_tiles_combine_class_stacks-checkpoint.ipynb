{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open image files\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import ndimage\n",
    "import pickle\n",
    "from skimage.transform import rescale \n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from mayavi import mlab\n",
    "from nifti import *\n",
    "import nifti.clib as ncl\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from skimage.measure import grid_points_in_poly\n",
    "from skimage.measure import find_contours\n",
    "from skimage.filters import gaussian_filter\n",
    "\n",
    "d = 'sargentii_17'\n",
    "\n",
    "files = []\n",
    "for file in glob.glob(d+'/*.ti*'):\n",
    "    files.append(file)\n",
    "\n",
    "# open first image to get the image dimensions\n",
    "im = np.array(Image.open(files[0]))\n",
    "\n",
    "# define image_stack array\n",
    "image_stack = np.zeros([len(files),np.shape(im)[0],np.shape(im)[1]])\n",
    "# read and standardize all images\n",
    "for i in range(len(files)):\n",
    "    im = np.array(Image.open(files[i]))        \n",
    "\n",
    "    image_stack[i,:,:] = im\n",
    "    \n",
    "# the contour of every step_size-th frame will be searched\n",
    "step_size = 10\n",
    "\n",
    "size = 50\n",
    "var = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:73: DeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "[3L, 310L, 334L, 496L, 1L, 1L, 1L, 1L]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f = open('data_files/class_stack_'+str(size)+'x'+str(size)+'_var0'+str(int(var*100e0))+'.dat','r')\n",
    "[class_stack_d1] = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('data_files/class_stack_'+str(size)+'x'+str(size)+'_var0'+str(int(var*100e0))+'_d2.dat','r')\n",
    "[class_stack_d2] = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('data_files/class_stack_'+str(size)+'x'+str(size)+'_var0'+str(int(var*100e0))+'_d3.dat','r')\n",
    "[class_stack_d3] = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "combine_d1 = np.zeros(np.shape(image_stack))\n",
    "combine_d2 = np.zeros(np.shape(image_stack))\n",
    "combine_d3 = np.zeros(np.shape(image_stack))\n",
    "\n",
    "for f in range(np.shape(image_stack)[0]):\n",
    "    shape1 = np.array(np.shape(combine_d1[f,:,:]))\n",
    "    shape2 = np.array(np.shape(class_stack_d1[f/step_size,:,:]))\n",
    "    combine_d1[f,:,:] = rescale(1e0*class_stack_d1[f/step_size,:,:],1e0*shape1/shape2)\n",
    "    \n",
    "for f in range(np.shape(image_stack)[1]):\n",
    "    shape1 = np.array(np.shape(combine_d1[:,f,:]))\n",
    "    shape2 = np.array(np.shape(class_stack_d2[f/step_size,:,:]))\n",
    "    combine_d2[:,f,:] = rescale(1e0*class_stack_d2[f/step_size,:,:],1e0*shape1/shape2)\n",
    "\n",
    "for f in range(np.shape(image_stack)[2]):\n",
    "    shape1 = np.array(np.shape(combine_d1[:,:,f]))\n",
    "    shape2 = np.array(np.shape(class_stack_d3[f/step_size,:,:]))\n",
    "    combine_d3[:,:,f] = rescale(1e0*class_stack_d3[f/step_size,:,:],1e0*shape1/shape2)\n",
    "\n",
    "combine = combine_d1 + combine_d2 + combine_d3\n",
    "\n",
    "combine[combine < 2] = 0\n",
    "combine[combine >= 2] = 1\n",
    "\n",
    "boundary = np.zeros(np.shape(image_stack))\n",
    "\n",
    "for f in range(np.shape(image_stack)[0]):\n",
    "    \n",
    "    if f%50 == 0:\n",
    "        print f\n",
    "    \n",
    "    smoothed = gaussian_filter(combine[f,:,:].astype(float),sigma=2*step_size)\n",
    "    \n",
    "    contours = find_contours(smoothed, 0.5)\n",
    "    \n",
    "    if len(contours) != 0:\n",
    "    \n",
    "        # calculate the area of the contours\n",
    "        area = np.zeros(len(contours))\n",
    "\n",
    "        for n, contour in enumerate(contours):\n",
    "            x = contour[:,0]\n",
    "            y = contour[:,1]\n",
    "            # copy the first point to the end of the contour list to close the loop\n",
    "            x = np.append(x,x[0])\n",
    "            y = np.append(y,y[0])\n",
    "            # use Green's theorem to calculate the area of the contour\n",
    "            area[n] = np.abs(np.sum(x[:-1]*y[1:]-y[:-1]*x[1:]))/2e0\n",
    "\n",
    "        # find contour with the largest area\n",
    "        cont = contours[np.where(area == np.max(area))[0]]\n",
    "    \n",
    "    pixels_in_cont = grid_points_in_poly(np.shape(image_stack[f,:,:]),cont)\n",
    "    \n",
    "    boundary[f,:,:] = image_stack[f,:,:]*pixels_in_cont\n",
    "    \n",
    "    if f%100 == 0:\n",
    "    \n",
    "        plt.axis('equal')\n",
    "        plt.xlim([0,np.shape(image_stack[f,:,:])[0]])\n",
    "        plt.ylim([0,np.shape(image_stack[f,:,:])[1]])\n",
    "        plt.imshow(boundary[f,:,:],cmap='Greys_r',vmin=0,vmax=66000)\n",
    "        plt.savefig('imgs/boundary_tiles_combined_'+str(f)+'.jpg',dpi=100)\n",
    "        plt.close()\n",
    "        \n",
    "nim = NiftiImage(zoom(boundary,0.5))\n",
    "print nim.header['dim']\n",
    "nim.header['datatype'] == ncl.NIFTI_TYPE_FLOAT64\n",
    "nim.save('data_files/'+d+'_combined.nii.gz')\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/ndimage/interpolation.py:549: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3L, 310L, 334L, 496L, 1L, 1L, 1L, 1L]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/nifti/image.py:231: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  return (not self._data == None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nim = NiftiImage('data_files/segmented_sargentii_17_combined.nii.gz').asarray()\n",
    "\n",
    "# march the cubes\n",
    "verts, faces = measure.marching_cubes(np.swapaxes(nim,0,2), 0.5)\n",
    "\n",
    "for i in range(360):\n",
    "    if i%36 == 0:\n",
    "        print i\n",
    "    # make the plot with mlab\n",
    "    mlab.triangular_mesh([vert[0] for vert in verts],\n",
    "              [vert[1] for vert in verts],\n",
    "              [vert[2] for vert in verts], faces) \n",
    "    mlab.view(azimuth = i)\n",
    "    mlab.savefig('animation_border/segmented/marching_cubes_combined_'+str(i).zfill(3)+'.png')\n",
    "    mlab.close()\n",
    "\n",
    "# create animation\n",
    "for i in range(np.shape(image_stack)[0]):\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        print i\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.axis('equal')\n",
    "    plt.title('original image')\n",
    "    plt.imshow(image_stack[i,:,:],cmap='Greys_r',vmin=0,vmax=66000)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.axis('equal')\n",
    "    plt.title('segmented image - leaf')\n",
    "    plt.imshow(zoom(nim[i/2,:,:],2e0),cmap='Greys_r')\n",
    "    plt.savefig('animation_border/segmented/segmented_combined_'+str(i).zfill(4)+'.png',dpi=100)\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
